{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM (Support Vector Machine)â€Š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1372, 5)\n",
      "------------\n",
      "   Variance  Skewness  Curtosis  Entropy  Class\n",
      "0   3.62160    8.6661   -2.8073 -0.44699      0\n",
      "1   4.54590    8.1674   -2.4586 -1.46210      0\n",
      "2   3.86600   -2.6383    1.9242  0.10645      0\n",
      "3   3.45660    9.5228   -4.0112 -3.59440      0\n",
      "4   0.32924   -4.4552    4.5718 -0.98880      0\n"
     ]
    }
   ],
   "source": [
    "# doing the minimum necessary imports\n",
    "# more modules would be imported as and when needed\n",
    "\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "%matplotlib inline\n",
    "\n",
    "# reading data from CSV file. \n",
    "# reading bank currency note data into pandas dataframe.\n",
    "bankdata = pd.read_csv(\"bill_authentication.csv\")  \n",
    "\n",
    "# Exploratory Data Analysis\n",
    "print(bankdata.shape)  \n",
    "print(\"------------\")\n",
    "print(bankdata.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[151   1]\n",
      " [  1 122]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       152\n",
      "           1       0.99      0.99      0.99       123\n",
      "\n",
      "    accuracy                           0.99       275\n",
      "   macro avg       0.99      0.99      0.99       275\n",
      "weighted avg       0.99      0.99      0.99       275\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing\n",
    "# Data preprocessing involves \n",
    "# (1) Dividing the data into attributes and labels and \n",
    "# (2) dividing the data into training and testing sets.\n",
    "\n",
    "# To divide the data into attributes and labels, do :\n",
    "X = bankdata.drop('Class', axis=1)  \n",
    "y = bankdata['Class']  \n",
    "\n",
    "# the final preprocessing step is to divide data into training and test sets\n",
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state=10)\n",
    "\n",
    "\n",
    "# Training the Algorithm. Here we would use simple SVM , \n",
    "# i.e linear SVM\n",
    "from sklearn.svm import SVC  \n",
    "\n",
    "svclassifier = SVC(kernel='linear')  # classifying linear data\n",
    "# kernel can take many values like\n",
    "# Gaussian, polynomial, sigmoid, or computable kernel\n",
    "# default kernel = rbf ( Radial Basis Function)\n",
    "\n",
    "svclassifier.fit(X_train, y_train)  \n",
    "\n",
    "# Making Predictions\n",
    "y_pred = svclassifier.predict(X_test)\n",
    "\n",
    "# Evaluating the Algorithm\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "\n",
    "print(classification_report(y_test,y_pred)) \n",
    "\n",
    "# Remember : for evaluating classification-based ML algo use  \n",
    "# confusion_matrix, classification_report and accuracy_score.\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Applying SVM over non-linear data\n",
    " \n",
    "In case of non-linearly separable data, the simple SVM algorithm cannot be used. Rather, a modified version of SVM, called Kernel SVM, is used.\n",
    "\n",
    "Basically, the kernel SVM projects the non-linearly separable data in lower dimensions to linearly separable data in higher dimensions in such a way that data points belonging to different classes are allocated to different dimensions. Again, there is complex mathematics involved in this, but you do not have to worry about it in order to use SVM. Rather we can simply use Python's Scikit-Learn library to implement and use the kernel SVM.\n",
    "\n",
    "Implementing Kernel SVM with Scikit-Learn is similar to the simple SVM. In this section, we will use the famous iris dataset to predict the category to which a plant belongs based on four attributes: sepal-width, sepal-length, petal-width and petal-length.\n",
    "\n",
    "We will try all three possible kernels; namely polynomial, Gaussian, and sigmoid kernels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "\n",
    "# import some data to play with\n",
    "irisdata = sns.load_dataset('iris')\n",
    "irisdata.head()  # have a look at the attributres(=> X) and Labels(=> y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing data\n",
    "X = irisdata.drop('species', axis=1)  \n",
    "y = irisdata['species']\n",
    "\n",
    "# Train Test Split\n",
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state=10)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Algorithm\n",
    "To train the kernel SVM, we use the same SVC class of the Scikit-Learn's svm library.\n",
    "\n",
    "We will implement polynomial, Gaussian, and sigmoid kernels to see which one works better for our problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Polynomial Kernel\n",
    "\n",
    "See this https://slideplayer.com/slide/9163126/27/images/8/Graphs+of+Polynomial+Functions.jpg\n",
    "\n",
    "In the case of polynomial kernel, you also have to pass a value for the degree parameter of the SVC class. This basically is the degree of the polynomial. Take a look at how we can use a polynomial kernel to implement kernel SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10  0  0]\n",
      " [ 0 12  1]\n",
      " [ 0  0  7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       1.00      0.92      0.96        13\n",
      "   virginica       0.88      1.00      0.93         7\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.96      0.97      0.96        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC  \n",
    "svclassifier = SVC(kernel='poly', degree=8, gamma='auto')  \n",
    "# gamma is optional. But it gives a FutureWarning. To avoid it , specify\n",
    "# gamma as 'auto' or 'scale'\n",
    "\n",
    "svclassifier.fit(X_train, y_train)\n",
    "\n",
    "# Making Predictions\n",
    "# Now once we have trained the algorithm, \n",
    "# the next step is to make predictions on the test data.\n",
    "y_pred = svclassifier.predict(X_test)  \n",
    "\n",
    "\n",
    "# Evaluating the Algorithm\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Note : Note the misclassification in 'virginica' species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Gaussian Kernel\n",
    "\n",
    "To use Gaussian kernel, you have to specify 'rbf' as value for the Kernel parameter of the SVC class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0  7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       1.00      1.00      1.00        13\n",
      "   virginica       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC  \n",
    "svclassifier = SVC(kernel='rbf', gamma='auto')  \n",
    "svclassifier.fit(X_train, y_train) \n",
    "\n",
    "# Prediction and Evaluation\n",
    "y_pred = svclassifier.predict(X_test)  \n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred))  \n",
    "\n",
    "# Note : Note the best performance thats 100% precise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Sigmoid Kernel\n",
    "Finally, let's use a sigmoid kernel for implementing Kernel SVM. \n",
    "To use the sigmoid kernel, you have to specify 'sigmoid' as value for the kernel parameter of the SVC class.Take a look at the following script:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0 10]\n",
      " [ 0  0 13]\n",
      " [ 0  0  7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       0.00      0.00      0.00        10\n",
      "  versicolor       0.00      0.00      0.00        13\n",
      "   virginica       0.23      1.00      0.38         7\n",
      "\n",
      "    accuracy                           0.23        30\n",
      "   macro avg       0.08      0.33      0.13        30\n",
      "weighted avg       0.05      0.23      0.09        30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sachin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Sachin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Sachin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC  \n",
    "svclassifier = SVC(kernel='sigmoid', gamma='auto')  \n",
    "svclassifier.fit(X_train, y_train)\n",
    "\n",
    "# Prediction and Evaluation\n",
    "y_pred = svclassifier.predict(X_test)  \n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Note : Note the very poor perfomance from Sigmoid kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of Kernel Performance\n",
    "\n",
    "If we compare the performance of the different types of kernels we can clearly see that the sigmoid kernel performs the worst. This is due to the reason that sigmoid function returns two values, 0 and 1, therefore it is more suitable for binary classification problems. However, in our case we had three output classes.\n",
    "\n",
    "Amongst the Gaussian kernel and polynomial kernel, we can see that Gaussian kernel achieved a perfect 100% prediction rate while polynomial kernel misclassified three instances. Therefore the Gaussian kernel performed slightly better. However, there is no hard and fast rule as to which kernel performs best in every scenario. It is all about testing all the kernels and selecting the one with the best results on your test dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
